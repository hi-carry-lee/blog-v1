import {
  generateEmbedding,
  batchGenerateEmbeddings,
  chunkText,
  countTokens,
  MAX_TOKENS,
} from "../ai/embedding";
import {
  insertEmbedding,
  batchInsertEmbeddings,
  deleteEmbeddingsByPostId,
  searchSimilarEmbeddings,
} from "../vector";
import { prisma } from "../db";

export interface Post {
  id: string;
  title: string;
  content: string;
}

/**
 * ä¸ºæ–‡ç« ç”Ÿæˆæ‰€æœ‰ embeddings
 */
export async function generatePostEmbeddings(post: Post) {
  try {
    const { id, title, content } = post;

    // 1. ç”Ÿæˆæ ‡é¢˜ embeddingï¼ˆæ€»æ˜¯å•ç‹¬ä¸€æ¡ï¼‰
    const titleEmbedding = await generateEmbedding(title);
    const titleTokens = countTokens(title);

    await insertEmbedding({
      postId: id,
      contentType: "title",
      textChunk: title,
      embedding: titleEmbedding,
      tokenCount: titleTokens,
    });

    // 2. å¤„ç†æ­£æ–‡ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—
    const contentTokens = countTokens(content);

    if (contentTokens <= MAX_TOKENS) {
      // æ­£æ–‡è¾ƒçŸ­ï¼Œæ•´ä½“ embed
      const contentEmbedding = await generateEmbedding(content);
      await insertEmbedding({
        postId: id,
        contentType: "content",
        textChunk: content,
        embedding: contentEmbedding,
        tokenCount: contentTokens,
      });
    } else {
      // æ­£æ–‡è¾ƒé•¿ï¼Œéœ€è¦åˆ†å—
      console.log(`ğŸ“š Post ${id} is long, chunking...`);
      const chunks = chunkText(content, {
        maxTokens: 500,
        overlap: 50,
      });

      // æ‰¹é‡ç”Ÿæˆ embeddingsï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
      const chunkTexts = chunks.map((c) => c.text);
      const chunkEmbeddings = await batchGenerateEmbeddings(chunkTexts);

      // æ‰¹é‡æ’å…¥æ•°æ®åº“
      await batchInsertEmbeddings(
        chunks.map((chunk, index) => ({
          postId: id,
          contentType: "chunk" as const,
          textChunk: chunk.text,
          embedding: chunkEmbeddings[index],
          chunkIndex: chunk.index,
          tokenCount: chunk.tokenCount,
        }))
      );

      console.log(`âœ… Generated ${chunks.length} chunks for post ${id}`);
    }
  } catch (error) {
    console.error(`Failed to generate embeddings for post ${post.id}:`, error);
    throw error;
  }
}

/**
 * æ›´æ–°æ–‡ç« çš„ embeddings
 */
export async function updatePostEmbeddings(post: Post) {
  console.log(`ğŸ”„ Updating embeddings for post ${post.id}`);

  // 1. åˆ é™¤æ—§æ•°æ®
  await deleteEmbeddingsByPostId(post.id);

  // 2. é‡æ–°ç”Ÿæˆ
  await generatePostEmbeddings(post);

  console.log(`âœ… Updated embeddings for post ${post.id}`);
}

/**
 * æœç´¢æ–‡ç« ï¼ˆå»é‡ + æ’åºï¼‰
 */
export async function searchPosts(
  query: string,
  options: {
    limit?: number;
    minSimilarity?: number;
    page?: number;
    onlyPublished?: boolean;
  } = {}
) {
  const {
    limit = 10,
    minSimilarity = 0.5,
    page = 1,
    onlyPublished = true,
  } = options; // ä¸´æ—¶é™ä½åˆ° 0.3 è¿›è¡Œæµ‹è¯•

  try {
    // 1. Generate query embedding
    const queryEmbedding = await generateEmbedding(query);

    // 2. Vector search
    const results = await searchSimilarEmbeddings(queryEmbedding, {
      limit: limit * 2, // Get more for deduplication
      minSimilarity,
    });
    // 3. Deduplicate by post
    const uniquePosts = new Map<string, (typeof results)[0]>();
    for (const result of results) {
      const existing = uniquePosts.get(result.post_id);
      if (!existing || result.similarity > existing.similarity) {
        uniquePosts.set(result.post_id, result);
      }
    }

    // 4. Get full post data for the unique posts
    const postIds = Array.from(uniquePosts.keys());
    const posts = await prisma.post.findMany({
      where: {
        id: { in: postIds },
        ...(onlyPublished && { published: true }), // å¯é€‰çš„å‘å¸ƒçŠ¶æ€è¿‡æ»¤
      },
      include: {
        category: {
          select: { id: true, name: true, slug: true },
        },
        author: {
          select: { id: true, name: true, image: true },
        },
        tags: {
          select: { id: true, name: true, slug: true },
        },
      },
      orderBy: { publishedAt: "desc" },
    });

    // 5. Combine with search metadata
    const enrichedPosts = posts.map((post) => {
      const searchResult = uniquePosts.get(post.id);
      return {
        ...post,
        similarity: searchResult?.similarity || 0,
        snippet: searchResult?.text_chunk?.slice(0, 200) + "..." || post.brief,
      };
    });

    // 6. Sort by similarity and apply pagination
    const sortedPosts = enrichedPosts
      .sort((a, b) => b.similarity - a.similarity)
      .slice((page - 1) * limit, page * limit);

    const totalPages = Math.ceil(enrichedPosts.length / limit);

    return {
      success: true,
      posts: sortedPosts,
      totalCount: enrichedPosts.length,
      currentPage: page,
      totalPages,
      searchQuery: query,
    };
  } catch (error) {
    console.error("Search posts error:", error);
    return {
      success: false,
      posts: [],
      totalCount: 0,
      currentPage: page,
      totalPages: 0,
      searchQuery: query,
    };
  }
}
